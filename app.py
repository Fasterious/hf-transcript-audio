import gradio as gr
import whisperx
import torch
import tempfile
import json
import os
from datetime import datetime
from pathlib import Path
import gc

# Configuration
device = "cuda" if torch.cuda.is_available() else "cpu"
compute_type = "float16" if torch.cuda.is_available() else "float32"

# Variables globales pour les mod√®les
whisper_model = None
diarize_model = None
align_model = None
align_metadata = None

def load_models():
    """Charge tous les mod√®les n√©cessaires"""
    global whisper_model, diarize_model, align_model, align_metadata
    
    try:
        # 1. Mod√®le Whisper
        print("Chargement du mod√®le Whisper...")
        whisper_model = whisperx.load_model("large-v3", device, compute_type=compute_type)
        
        # 2. Mod√®le d'alignement (sera charg√© dynamiquement selon la langue)
        print("Mod√®les charg√©s avec succ√®s!")
        
        return True
    except Exception as e:
        print(f"Erreur lors du chargement des mod√®les: {e}")
        return False

def load_alignment_model(language_code):
    """Charge le mod√®le d'alignement pour une langue sp√©cifique"""
    global align_model, align_metadata
    try:
        align_model, align_metadata = whisperx.load_align_model(
            language_code=language_code, 
            device=device
        )
        return True
    except Exception as e:
        print(f"Erreur chargement alignement {language_code}: {e}")
        return False

def load_diarization_model():
    """Charge le mod√®le de diarisation"""
    global diarize_model
    try:
        # Utilise le token HF si disponible
        hf_token = os.getenv("HF_TOKEN")
        if hf_token:
            diarize_model = whisperx.DiarizationPipeline(
                use_auth_token=hf_token,
                device=device
            )
            return True
        else:
            print("Token HF manquant pour la diarisation")
            return False
    except Exception as e:
        print(f"Erreur chargement diarisation: {e}")
        return False

def format_timestamp(seconds):
    """Convertit les secondes en format timestamp SRT"""
    if seconds is None:
        return "00:00:00,000"
    
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"

def generate_srt_content(segments):
    """G√©n√®re le contenu SRT avec speakers si disponible"""
    srt_content = ""
    segment_counter = 1
    
    for segment in segments:
        start_time = format_timestamp(segment.get('start'))
        end_time = format_timestamp(segment.get('end'))
        text = segment.get('text', '').strip()
        speaker = segment.get('speaker', '')
        
        if text:
            srt_content += f"{segment_counter}\n"
            srt_content += f"{start_time} --> {end_time}\n"
            
            # Ajoute le speaker si disponible
            if speaker:
                srt_content += f"[{speaker}] {text}\n\n"
            else:
                srt_content += f"{text}\n\n"
            
            segment_counter += 1
    
    return srt_content

def transcribe_with_whisperx(audio_file, language="auto", enable_diarization=True):
    """Transcription compl√®te avec WhisperX"""
    
    if not whisper_model:
        return "Erreur: Mod√®les non charg√©s", "", "", ""
    
    try:
        # 1. Transcription de base
        print("√âtape 1: Transcription...")
        audio = whisperx.load_audio(audio_file)
        
        if language == "auto":
            result = whisper_model.transcribe(audio, batch_size=16)
            detected_language = result["language"]
        else:
            result = whisper_model.transcribe(audio, batch_size=16, language=language)
            detected_language = language
        
        print(f"Langue d√©tect√©e/utilis√©e: {detected_language}")
        
        # 2. Alignement pour am√©liorer les timestamps
        print("√âtape 2: Alignement des timestamps...")
        if load_alignment_model(detected_language):
            result = whisperx.align(result["segments"], align_model, align_metadata, 
                                 audio, device, return_char_alignments=False)
        
        segments = result["segments"]
        
        # 3. Diarisation (s√©paration des locuteurs) si demand√©e
        speakers_info = ""
        if enable_diarization:
            print("√âtape 3: Diarisation (identification des locuteurs)...")
            if load_diarization_model():
                diarize_segments = diarize_model(audio)
                result = whisperx.assign_word_speakers(diarize_segments, result)
                segments = result["segments"]
                
                # Compte les locuteurs
                speakers = set()
                for segment in segments:
                    if 'speaker' in segment:
                        speakers.add(segment['speaker'])
                
                if speakers:
                    speakers_info = f"\nüéôÔ∏è Locuteurs identifi√©s: {', '.join(sorted(speakers))}\n"
        
        # G√©n√©ration des diff√©rents formats
        full_text = ""
        timestamped_text = ""
        
        for segment in segments:
            text = segment.get('text', '').strip()
            start = segment.get('start')
            end = segment.get('end')
            speaker = segment.get('speaker', '')
            
            if text:
                # Texte brut
                full_text += text + " "
                
                # Texte horodat√©
                start_str = format_timestamp(start).replace(',', '.')
                end_str = format_timestamp(end).replace(',', '.')
                
                if speaker:
                    timestamped_text += f"[{start_str} ‚Üí {end_str}] [{speaker}] {text}\n\n"
                else:
                    timestamped_text += f"[{start_str} ‚Üí {end_str}] {text}\n\n"
        
        # G√©n√©ration SRT
        srt_content = generate_srt_content(segments)
        
        # JSON d√©taill√©
        json_output = {
            "language": detected_language,
            "duration": max([seg.get('end', 0) for seg in segments]) if segments else 0,
            "speakers_detected": len(set(seg.get('speaker', '') for seg in segments if seg.get('speaker'))),
            "segments": segments,
            "full_text": full_text.strip(),
            "transcription_date": datetime.now().isoformat(),
            "model_info": {
                "whisper_model": "large-v3",
                "diarization_enabled": enable_diarization,
                "alignment_enabled": True
            }
        }
        
        json_content = json.dumps(json_output, indent=2, ensure_ascii=False)
        
        # Nettoyage m√©moire
        del audio
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        success_msg = f"‚úÖ Transcription termin√©e!\nüåç Langue: {detected_language}{speakers_info}"
        return success_msg + "\n" + full_text.strip(), timestamped_text, srt_content, json_content
        
    except Exception as e:
        error_msg = f"‚ùå Erreur lors de la transcription: {str(e)}"
        return error_msg, "", "", ""

def create_download_files(text_content, srt_content, json_content):
    """Cr√©e les fichiers temporaires pour t√©l√©chargement"""
    files = []
    
    try:
        if text_content and not text_content.startswith("‚ùå"):
            # Fichier texte
            txt_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', 
                                                 delete=False, encoding='utf-8')
            # Nettoie le texte des √©mojis et infos pour le fichier
            clean_text = text_content.split('\n', 1)[-1] if '\n' in text_content else text_content
            txt_file.write(clean_text)
            txt_file.close()
            files.append(txt_file.name)
            
            # Fichier SRT
            if srt_content:
                srt_file = tempfile.NamedTemporaryFile(mode='w', suffix='.srt', 
                                                     delete=False, encoding='utf-8')
                srt_file.write(srt_content)
                srt_file.close()
                files.append(srt_file.name)
            
            # Fichier JSON
            if json_content:
                json_file = tempfile.NamedTemporaryFile(mode='w', suffix='.json', 
                                                      delete=False, encoding='utf-8')
                json_file.write(json_content)
                json_file.close()
                files.append(json_file.name)
    
    except Exception as e:
        print(f"Erreur cr√©ation fichiers: {e}")
    
    return files

def process_audio(audio_file, language, enable_diarization, progress=gr.Progress()):
    """Traite l'audio avec barre de progression"""
    
    if audio_file is None:
        return "‚ùå Veuillez s√©lectionner un fichier audio", "", "", "", []
    
    progress(0.1, desc="Chargement du fichier...")
    
    # Transcription
    progress(0.3, desc="Transcription en cours...")
    result_text, timestamped_text, srt_content, json_content = transcribe_with_whisperx(
        audio_file, language, enable_diarization
    )
    
    progress(0.9, desc="G√©n√©ration des fichiers...")
    
    # Cr√©ation des fichiers de t√©l√©chargement
    download_files = create_download_files(result_text, srt_content, json_content)
    
    progress(1.0, desc="Termin√©!")
    
    return result_text, timestamped_text, srt_content, json_content, download_files

# Interface Gradio
def create_interface():
    with gr.Blocks(title="WhisperX Pro - Transcription avec Diarisation", 
                   theme=gr.themes.Soft()) as interface:
        
        gr.Markdown("""
        # üéôÔ∏è WhisperX Pro - Transcription Avanc√©e
        
        **Transcription professionnelle avec s√©paration des locuteurs**
        
        ‚ú® Fonctionnalit√©s :
        - üó£Ô∏è **Diarisation** : Identification automatique des locuteurs  
        - ‚è∞ **Alignement pr√©cis** : Timestamps optimis√©s
        - üåç **Multilingue** : Plus de 100 langues support√©es
        - üìÅ **Multi-export** : TXT, SRT, JSON
        """)
        
        # Status de chargement des mod√®les
        model_status = gr.Markdown("üîÑ Chargement des mod√®les en cours...")
        
        with gr.Row():
            with gr.Column(scale=1):
                audio_input = gr.Audio(
                    label="üìÅ Fichier Audio/Vid√©o",
                    type="filepath"
                )
                
                language_select = gr.Dropdown(
                    label="üåç Langue",
                    choices=[
                        ("D√©tection automatique", "auto"),
                        ("Fran√ßais", "fr"),
                        ("Anglais", "en"),
                        ("Espagnol", "es"),
                        ("Italien", "it"),
                        ("Allemand", "de"),
                        ("Portugais", "pt"),
                        ("Chinois", "zh"),
                        ("Japonais", "ja"),
                        ("Arabe", "ar")
                    ],
                    value="auto"
                )
                
                diarization_checkbox = gr.Checkbox(
                    label="üé≠ Activer la diarisation (s√©paration des locuteurs)",
                    value=True,
                    info="Identifie et s√©pare les diff√©rents locuteurs"
                )
                
                transcribe_btn = gr.Button(
                    "üöÄ Transcrire avec WhisperX",
                    variant="primary",
                    size="lg"
                )
            
            with gr.Column(scale=2):
                with gr.Tabs():
                    with gr.Tab("üìù R√©sultat"):
                        text_output = gr.Textbox(
                            label="Transcription",
                            lines=12,
                            max_lines=20,
                            show_copy_button=True
                        )
                    
                    with gr.Tab("‚è∞ Horodatage"):
                        timestamped_output = gr.Textbox(
                            label="Transcription horodat√©e avec locuteurs",
                            lines=12,
                            max_lines=20,
                            show_copy_button=True
                        )
                    
                    with gr.Tab("üé¨ SRT"):
                        srt_output = gr.Textbox(
                            label="Sous-titres SRT",
                            lines=12,
                            max_lines=20,
                            show_copy_button=True
                        )
                    
                    with gr.Tab("üìä JSON"):
                        json_output = gr.Textbox(
                            label="Export JSON d√©taill√©",
                            lines=12,
                            max_lines=20,
                            show_copy_button=True
                        )
                
                download_files = gr.File(
                    label="üì• T√©l√©charger les fichiers",
                    file_count="multiple",
                    visible=False
                )
        
        # √âv√©nements
        transcribe_btn.click(
            fn=process_audio,
            inputs=[audio_input, language_select, diarization_checkbox],
            outputs=[text_output, timestamped_output, srt_output, json_output, download_files]
        ).then(
            fn=lambda: gr.update(visible=True),
            outputs=[download_files]
        )
        
        gr.Markdown("""
        ## ‚öôÔ∏è Configuration requise
        
        - **Token Hugging Face** : N√©cessaire pour la diarisation (mod√®les pyannote)
        - **GPU recommand√©** : Pour de meilleures performances
        - **Formats support√©s** : MP3, WAV, MP4, M4A, FLAC, etc.
        
        ## üéØ Optimis√© pour
        
        - Interviews et entretiens
        - R√©unions et conf√©rences  
        - Podcasts multi-locuteurs
        - Tests utilisateurs
        """)
        
        # Mise √† jour du status au chargement
        interface.load(
            fn=lambda: "‚úÖ Mod√®les charg√©s - Pr√™t √† transcrire!" if load_models() else "‚ùå Erreur de chargement des mod√®les",
            outputs=[model_status]
        )
    
    return interface

if __name__ == "__main__":
    interface = create_interface()
    interface.launch(server_name="0.0.0.0", server_port=7860)
